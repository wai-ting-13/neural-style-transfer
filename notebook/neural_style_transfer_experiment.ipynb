{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Xi4N8oajTyS"
   },
   "source": [
    "# Jupyter Note - Neural Style Transfer using VGG Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5TdH1gj_e1B"
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1757132619628,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "f76bONpYjTyW",
    "outputId": "cceea3c6-a901-42ce-d2f0-da858a987d0d"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import tqdm\n",
    "\n",
    "# Print Library Version\n",
    "print(f\"Python version={sys.version}\")\n",
    "print(f\"torch version={torch.__version__}\")\n",
    "print(f\"torchvision version={torchvision.__version__}\")\n",
    "print(f\"matplotlib version={matplotlib.__version__}\")\n",
    "print(f\"tdqm version={tqdm.__version__}\")\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxXpZLxFGTn_"
   },
   "source": [
    "# Define Necessary Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQSjO48wjTyY"
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1757132441014,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "R7Hv-4l0GToA"
   },
   "outputs": [],
   "source": [
    "\"\"\"Model Definition\"\"\"\n",
    "class NSTNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_extractor : nn.Module,\n",
    "        style_layer_names : list[str],\n",
    "        content_layer_names : list[str],\n",
    "        use_avgpool : bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Get Indices\n",
    "        self.style_loss_indices = [i for i, _ in enumerate(style_layer_names)]\n",
    "        self.content_loss_indices = [i for i, name in enumerate(style_layer_names) if name in content_layer_names]\n",
    "\n",
    "        # Define Normalisation Function\n",
    "        self.normalise = torchvision.transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "\n",
    "        slices : list[nn.Sequencial] = []\n",
    "        slice = nn.Sequential()\n",
    "\n",
    "        i = 0;\n",
    "        for layer in feature_extractor.children():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                i += 1\n",
    "                name = 'conv_{}'.format(i)\n",
    "            elif isinstance(layer, nn.ReLU):\n",
    "                name = 'relu_{}'.format(i)\n",
    "                layer = nn.ReLU(inplace=False)\n",
    "            elif isinstance(layer, nn.MaxPool2d):\n",
    "                name = 'pool_{}'.format(i)\n",
    "                layer = nn.AvgPool2d(layer.kernel_size, layer.stride, layer.padding) if use_avgpool else layer\n",
    "            elif isinstance(layer, nn.BatchNorm2d):\n",
    "                name = 'bn_{}'.format(i)\n",
    "            else:\n",
    "                raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
    "\n",
    "            slice.add_module(name, layer)\n",
    "            \n",
    "            if name in style_layer_names:\n",
    "                slices.append(slice)\n",
    "                slice = nn.Sequential()\n",
    "\n",
    "        self.extractor = nn.Sequential()\n",
    "        for i, slice in enumerate(slices,1):\n",
    "            self.extractor.add_module(f\"slice_{i}\", slice)\n",
    "\n",
    "    def forward(self, x) -> list[torch.Tensor]:\n",
    "        x = self.normalise(x)\n",
    "        feature_maps : list[torch.Tensor] = []\n",
    "        for slice in self.extractor.children():\n",
    "            x = slice(x)\n",
    "            feature_maps.append(x)\n",
    "        return feature_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeBWnkT2GToB"
   },
   "source": [
    "## Gram Matrix for Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1757132441017,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "iiT4AzhwGToB"
   },
   "outputs": [],
   "source": [
    "# Define gram matrix\n",
    "def gram_matrix(ip : torch.Tensor) -> torch.Tensor:\n",
    "    num_batch, num_channels, height, width = ip.size()\n",
    "    feats = ip.view(num_batch * num_channels, width * height)\n",
    "    gram_mat = torch.mm(feats, feats.t())\n",
    "    return gram_mat.div(num_batch * num_channels * width * height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hq_m7dnVGToC"
   },
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcBq8QgVGToC"
   },
   "source": [
    "### Model Preparaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1757132441037,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "R_U3M5Z7GToC"
   },
   "outputs": [],
   "source": [
    "def prepare_model(\n",
    "    device,\n",
    "    feature_extractor : nn.Module,\n",
    "    style_layer_names: list[str],\n",
    "    content_layer_names: list[str],\n",
    "    use_avgpool : bool = False\n",
    ") -> nn.Module:\n",
    "    # Define Our Model\n",
    "    net = NSTNetwork(\n",
    "        feature_extractor=feature_extractor,\n",
    "        style_layer_names=style_layer_names,\n",
    "        content_layer_names=content_layer_names,\n",
    "        use_avgpool=use_avgpool\n",
    "    )\n",
    "\n",
    "    # Disable Gradient and Turn Model to Evaluation Model\n",
    "    net.requires_grad_(False)\n",
    "    net.eval()\n",
    "    net.to(device)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFs1WL4bGToC"
   },
   "source": [
    "### Import image and convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1757132441052,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "ydwMvLt2GToD"
   },
   "outputs": [],
   "source": [
    "BIG_DIM=512\n",
    "SMALL_DIM=128\n",
    "image_dimension = BIG_DIM if torch.cuda.is_available() else SMALL_DIM\n",
    "\n",
    "def image_to_tensor(image_filepath : str, image_dimension : int = SMALL_DIM) -> torch.Tensor:\n",
    "    img = Image.open(image_filepath).convert('RGB')\n",
    "\n",
    "    print(f\"Original image size: {img.size}\")\n",
    "\n",
    "    # display image to check\n",
    "    _, axs = plt.subplots(1,2, figsize=(10, 6))\n",
    "    axs[0].set_title(f\"{image_filepath}\")\n",
    "    axs[0].imshow(img)\n",
    "\n",
    "    # Central-crop the image if it is not square\n",
    "    if img.height != img.width:\n",
    "        width, height = img.size\n",
    "        min_dim = min(width, height)\n",
    "        left = (width - min_dim) / 2\n",
    "        top = (height - min_dim) / 2\n",
    "        right = (width + min_dim) / 2\n",
    "        bottom = (height + min_dim) / 2\n",
    "        box = (left, top, right, bottom)\n",
    "        img = img.crop(box)\n",
    "\n",
    "    # Scale-up image if it is too small\n",
    "    if img.height < image_dimension or img.width < image_dimension:\n",
    "      scaling_factor = image_dimension / max(img.size)\n",
    "\n",
    "      new_width = int(img.width * scaling_factor)\n",
    "      new_height = int(img.height * scaling_factor)\n",
    "\n",
    "      img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "\n",
    "    print(f\"New image size: {img.size}\")\n",
    "\n",
    "    torch_transformation = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(image_dimension),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    img = torch_transformation(img).unsqueeze(0)\n",
    "\n",
    "    # Display Processed Image, Sub plt\n",
    "    axs[1].set_title(f\"{image_filepath} Processed\")\n",
    "    axs[1].imshow(img.squeeze(0).cpu().detach().numpy().transpose(1,2,0))\n",
    "\n",
    "    return img.to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmLU8Pq5GToD"
   },
   "source": [
    "## Style Transfering Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1757132625146,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "a0FTchWMGToD"
   },
   "outputs": [],
   "source": [
    "def style_transfer(\n",
    "    # neural network\n",
    "    net : nn.Module,\n",
    "    # Inputs\n",
    "    input_image : torch.Tensor,\n",
    "    content_image : torch.Tensor,\n",
    "    style_image : torch.Tensor,\n",
    "\n",
    "    # Optimiser\n",
    "    lr : float,\n",
    "\n",
    "    # loss function\n",
    "    wt_style : float,\n",
    "    wt_content : float,\n",
    "\n",
    "    # Transfering Process\n",
    "    num_epochs : int,\n",
    "    loss_saving_freq : int,\n",
    "    img_saving_freq : int,\n",
    "\n",
    "    output_path : str\n",
    ") -> Tuple[list[float], list[float]]:\n",
    "\n",
    "    # Clean Output Directory\n",
    "    if os.path.exists(output_path):\n",
    "        shutil.rmtree(output_path) # Deletes the directory and all its contents\n",
    "    os.makedirs(output_path) # Re-creates the empty directory\n",
    "\n",
    "    input_image.requires_grad_(True)\n",
    "\n",
    "    opt = optim.LBFGS([input_image], lr=lr)\n",
    "\n",
    "    epoch_style_losses = []\n",
    "    epoch_content_losses = []\n",
    "\n",
    "    for curr_epoch in range(1, num_epochs+1):\n",
    "\n",
    "        input_image.data.clamp_(0, 1)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        epoch_style_loss = 0\n",
    "        epoch_content_loss = 0\n",
    "\n",
    "        x = input_image\n",
    "        yc = content_image.detach()\n",
    "        ys = style_image.detach()\n",
    "\n",
    "        feature_maps_x = net(x)\n",
    "        with torch.no_grad():\n",
    "            feature_maps_yc = net(yc)\n",
    "            feature_maps_ys = net(ys)\n",
    "\n",
    "        for i,(f_x,f_yc,f_ys) in enumerate(zip(feature_maps_x,feature_maps_yc,feature_maps_ys)):\n",
    "            if i in net.style_loss_indices:\n",
    "                epoch_style_loss += F.mse_loss(gram_matrix(f_x), gram_matrix(f_ys.detach()).detach())\n",
    "            if i in net.content_loss_indices:\n",
    "                epoch_content_loss += F.mse_loss(f_x, f_yc.detach())\n",
    "\n",
    "        epoch_style_loss *= wt_style\n",
    "        epoch_content_loss *= wt_content\n",
    "\n",
    "        total_loss = epoch_style_loss + epoch_content_loss\n",
    "        total_loss.backward()\n",
    "\n",
    "        def closure() -> torch.Tensor:\n",
    "            return total_loss\n",
    "\n",
    "        if curr_epoch % loss_saving_freq == 0:\n",
    "            epoch_style_losses += [epoch_style_loss.cpu().detach().numpy()]\n",
    "            epoch_content_losses += [epoch_content_loss.cpu().detach().numpy()]\n",
    "            print(f\"epoch number {curr_epoch}\")\n",
    "            print(f\"style loss = {epoch_style_loss:.4f}, content loss = {epoch_content_loss:.4f}\")\n",
    "\n",
    "        if curr_epoch % img_saving_freq == 0:\n",
    "            display_image = input_image.data.clamp_(0, 1).squeeze(0).cpu().detach()\n",
    "            plt.figure()\n",
    "            plt.title(f\"epoch number {curr_epoch}\")\n",
    "            plt.imshow(display_image.numpy().transpose(1,2,0))\n",
    "            plt.show()\n",
    "            torchvision.utils.save_image(\n",
    "                display_image,\n",
    "                f\"{output_path}/image_{curr_epoch}.jpg\"\n",
    "            )\n",
    "\n",
    "        opt.step(closure=closure)\n",
    "\n",
    "    return (epoch_style_losses, epoch_content_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6cCL55PGToE"
   },
   "source": [
    "# Google Drive Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55039,
     "status": "ok",
     "timestamp": 1757132496107,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "26Ko5vqSGToE",
    "outputId": "7db5057c-716c-4fc8-f8e3-7fba1913ba51"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1757132496516,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "o_l-t7_3GToE",
    "outputId": "cebbe08f-4345-4410-fc52-99d42c3af8a3"
   },
   "outputs": [],
   "source": [
    "# Change the current working directory\n",
    "YOUR_WORKING_DIR_GDRIVE=\"MyDrive/Colab/neural-style-transfer/notebook\"\n",
    "\n",
    "import os;\n",
    "os.chdir(f\"/content/gdrive/{YOUR_WORKING_DIR_GDRIVE}\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVzt1GDH0iJ3"
   },
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-y6IE2yRGToF"
   },
   "source": [
    "## Select Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1757132496547,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "X7du4wiIGToF",
    "outputId": "6334a8d9-0898-4de9-f777-7d3a14ac92b0"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kjc_7QkJGToF"
   },
   "source": [
    "## Create Directories if not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1757132496641,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "AmVVRW8PGToG"
   },
   "outputs": [],
   "source": [
    "# Create Directory\n",
    "INPUT_PATH=\"./inputs\"\n",
    "OUTPUT_PATH=\"./outputs\"\n",
    "os.makedirs(INPUT_PATH, exist_ok=True) # Input Directory\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True) # Output Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f3Di82zGToG"
   },
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bi0DH7MhGToG"
   },
   "source": [
    "### Import pretrained model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4946,
     "status": "ok",
     "timestamp": 1757132501605,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "XxbgsFVrGToG",
    "outputId": "228a0ce0-32bb-4afd-8c87-949041b12bb4"
   },
   "outputs": [],
   "source": [
    "vgg19_model = torchvision.models.vgg19(weights=torchvision.models.vgg.VGG19_Weights.DEFAULT)\n",
    "# print(vgg19_model)\n",
    "\n",
    "vgg16_model = torchvision.models.vgg16(weights=torchvision.models.vgg.VGG16_Weights.DEFAULT)\n",
    "print(vgg16_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnlqTyddGToH"
   },
   "source": [
    "### Build Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1757132504248,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "1S1QBkgMGToH"
   },
   "outputs": [],
   "source": [
    "feature_extractor=vgg19_model.features\n",
    "style_layer_names=[\"relu_1\", \"relu_2\", \"relu_3\", \"relu_4\", \"relu_5\"]\n",
    "content_layer_names=[\"relu_4\"]\n",
    "use_avgpool=False\n",
    "\n",
    "net = prepare_model(\n",
    "    device,\n",
    "    feature_extractor=feature_extractor,\n",
    "    style_layer_names=style_layer_names,\n",
    "    content_layer_names=content_layer_names,\n",
    "    use_avgpool=use_avgpool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1757132505208,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "-ZaXN6C3GToH",
    "outputId": "8744f771-7aec-4036-c5a6-c06256a3a8ae"
   },
   "outputs": [],
   "source": [
    "# Print Network Aritechture\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJk3NzKsGToH"
   },
   "source": [
    "## Prepare Image Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 960
    },
    "executionInfo": {
     "elapsed": 1278,
     "status": "ok",
     "timestamp": 1757132632425,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "RNyGjXDqjTyX",
    "outputId": "ec7b6e3b-7fb4-47be-d37e-60edc9277b81"
   },
   "outputs": [],
   "source": [
    "# Get Style and Content Tensors\n",
    "style_image = image_to_tensor(f\"{INPUT_PATH}/style-1.jpg\", image_dimension).to(device).detach()\n",
    "content_image = image_to_tensor(f\"{INPUT_PATH}/content-4.jpeg\", image_dimension).to(device).detach()\n",
    "print(f\"style_image.shape: {style_image.shape}\")\n",
    "print(f\"content_image.shape: {content_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1757132634736,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "wkKVW1baGToI",
    "outputId": "f9a3b43a-9c9e-4936-e372-e68e16e72cef"
   },
   "outputs": [],
   "source": [
    "# Get Input Tensor\n",
    "init_mode = \"random\"\n",
    "\n",
    "if init_mode == \"content\":\n",
    "    # initialize as the content image\n",
    "    input_image = content_image.clone().to(device)\n",
    "else:\n",
    "    input_image = torch.randn(content_image.data.size(), device=device)\n",
    "\n",
    "# Display input image\n",
    "plt.figure()\n",
    "plt.title(\"Input Image\")\n",
    "plt.imshow(input_image.squeeze(0).cpu().detach().numpy().transpose(1,2,0).clip(0,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vV81v0KPA-wz"
   },
   "source": [
    "## Transfer the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1afFM9cfA0Qk18ZG5l4wLRhjxK1WU87Qm"
    },
    "executionInfo": {
     "elapsed": 45862,
     "status": "ok",
     "timestamp": 1757132682303,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "LusIJf2RjTya",
    "outputId": "62031ea4-3f88-4059-85cf-2d14a473f24d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lr=0.5\n",
    "\n",
    "wt_style=1e5\n",
    "wt_content=2\n",
    "\n",
    "num_epochs= 1000\n",
    "loss_saving_freq = 10\n",
    "img_saving_freq = 100\n",
    "\n",
    "epoch_style_losses, epoch_content_losses = style_transfer(\n",
    "    # Neural Network\n",
    "    net,\n",
    "\n",
    "    # Inputs\n",
    "    input_image,\n",
    "    content_image,\n",
    "    style_image,\n",
    "\n",
    "    # Optimiser\n",
    "    lr,\n",
    "\n",
    "    # loss function\n",
    "    wt_style,\n",
    "    wt_content,\n",
    "\n",
    "    # Transfering Process\n",
    "    num_epochs,\n",
    "    loss_saving_freq,\n",
    "    img_saving_freq,\n",
    "\n",
    "    OUTPUT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1k0EMCJykLA"
   },
   "source": [
    "### Plot Loss Curve for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 100,
     "status": "ok",
     "timestamp": 1757081497401,
     "user": {
      "displayName": "Wai Ting Hon",
      "userId": "18312159932542596713"
     },
     "user_tz": -480
    },
    "id": "ELHU23dcjTya",
    "outputId": "e986aa75-98d1-4ab9-bf07-da193f76f1a7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(loss_saving_freq, num_epochs+1, loss_saving_freq), epoch_style_losses, label='style_loss');\n",
    "plt.plot(range(loss_saving_freq, num_epochs+1, loss_saving_freq), epoch_content_losses, label='content_loss');\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch-test-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
